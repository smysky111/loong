{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp9lQNIvUg4d"
      },
      "source": [
        "# Working with the Loong environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V3aV16AmY0K"
      },
      "source": [
        "You can also check out this cookbook in Google Colab [here](https://colab.research.google.com/github/camel-ai/loong/blob/main/cookbooks/env_with_generator.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvHRdXwflAz-"
      },
      "source": [
        "<div class=\"align-center\">\n",
        "  <a href=\"https://www.camel-ai.org/\"><img src=\"https://i.postimg.cc/KzQ5rfBC/button.png\"width=\"150\"></a>\n",
        "  <a href=\"https://discord.camel-ai.org\"><img src=\"https://i.postimg.cc/L4wPdG9N/join-2.png\"  width=\"150\"></a></a>\n",
        "  \n",
        "‚≠ê <i>Star us on [*Github*](https://github.com/camel-ai/camel), join our [*Discord*](https://discord.camel-ai.org) or follow our [*X*](https://x.com/camelaiorg)\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZx1YuxtUIaT",
        "outputId": "a0fc1529-4efe-4db9-a180-4aef6981a433"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mDEPRECATION: git+https://github.com/camel-ai/camel.git@bec98152d3df3dd1731b78208608b4a9438a010e#egg=camel-ai[huggingface, data_tools] contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting camel-ai (from camel-ai[data_tools,huggingface])\n",
            "  Using cached camel_ai-0.2.38-py3-none-any.whl\n",
            "Requirement already satisfied: colorama<0.5,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (0.4.6)\n",
            "Requirement already satisfied: docstring-parser<0.16,>=0.15 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (0.15)\n",
            "Requirement already satisfied: httpx<1.0.0dev,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (0.28.1)\n",
            "Requirement already satisfied: jsonschema<5,>=4 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (4.23.0)\n",
            "Requirement already satisfied: openai<2,>=1.68.0 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (1.70.0)\n",
            "Requirement already satisfied: psutil<6,>=5.9.8 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (5.9.8)\n",
            "Requirement already satisfied: pydantic<2.10,>=1.9 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (2.9.2)\n",
            "Requirement already satisfied: tiktoken<0.8,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (0.7.0)\n",
            "Requirement already satisfied: aiosqlite<0.21,>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (0.20.0)\n",
            "Requirement already satisfied: datacommons-pandas<0.0.4,>=0.0.3 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (0.0.3)\n",
            "Requirement already satisfied: datacommons<2,>=1.4.3 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (1.4.3)\n",
            "Requirement already satisfied: math-verify<0.8,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (0.7.0)\n",
            "Requirement already satisfied: networkx<4,>=3.4.2 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (3.4.2)\n",
            "Requirement already satisfied: numpy~=1.26 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (1.26.4)\n",
            "Requirement already satisfied: pandas<2,>=1.5.3 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (1.5.3)\n",
            "Requirement already satisfied: rouge<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (1.0.1)\n",
            "Requirement already satisfied: stripe<12,>=11.3.0 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (11.6.0)\n",
            "Requirement already satisfied: textblob<0.18,>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (0.17.1)\n",
            "Requirement already satisfied: accelerate<0.27,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (0.26.1)\n",
            "Requirement already satisfied: datasets<4,>=3 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (3.5.0)\n",
            "Requirement already satisfied: diffusers<0.26,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (0.25.1)\n",
            "Requirement already satisfied: opencv-python<5,>=4 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (4.11.0.86)\n",
            "Requirement already satisfied: sentencepiece<0.3,>=0.2 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (0.2.0)\n",
            "Requirement already satisfied: soundfile<0.14,>=0.13 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (0.13.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers<5,>=4 in /usr/local/lib/python3.11/dist-packages (from camel-ai->camel-ai[data_tools,huggingface]) (4.50.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<0.27,>=0.26.0->camel-ai->camel-ai[data_tools,huggingface]) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate<0.27,>=0.26.0->camel-ai->camel-ai[data_tools,huggingface]) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate<0.27,>=0.26.0->camel-ai->camel-ai[data_tools,huggingface]) (0.30.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate<0.27,>=0.26.0->camel-ai->camel-ai[data_tools,huggingface]) (0.5.3)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.11/dist-packages (from aiosqlite<0.21,>=0.20.0->camel-ai->camel-ai[data_tools,huggingface]) (4.13.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from datacommons<2,>=1.4.3->camel-ai->camel-ai[data_tools,huggingface]) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<4,>=3->camel-ai->camel-ai[data_tools,huggingface]) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4,>=3->camel-ai->camel-ai[data_tools,huggingface]) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4,>=3->camel-ai->camel-ai[data_tools,huggingface]) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<4,>=3->camel-ai->camel-ai[data_tools,huggingface]) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets<4,>=3->camel-ai->camel-ai[data_tools,huggingface]) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<4,>=3->camel-ai->camel-ai[data_tools,huggingface]) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<4,>=3->camel-ai->camel-ai[data_tools,huggingface]) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets<4,>=3->camel-ai->camel-ai[data_tools,huggingface]) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets<4,>=3->camel-ai->camel-ai[data_tools,huggingface]) (3.11.15)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers<0.26,>=0.25.0->camel-ai->camel-ai[data_tools,huggingface]) (8.6.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers<0.26,>=0.25.0->camel-ai->camel-ai[data_tools,huggingface]) (2024.11.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers<0.26,>=0.25.0->camel-ai->camel-ai[data_tools,huggingface]) (11.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0dev,>=0.28.0->camel-ai->camel-ai[data_tools,huggingface]) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0dev,>=0.28.0->camel-ai->camel-ai[data_tools,huggingface]) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0dev,>=0.28.0->camel-ai->camel-ai[data_tools,huggingface]) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0dev,>=0.28.0->camel-ai->camel-ai[data_tools,huggingface]) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0dev,>=0.28.0->camel-ai->camel-ai[data_tools,huggingface]) (0.14.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5,>=4->camel-ai->camel-ai[data_tools,huggingface]) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5,>=4->camel-ai->camel-ai[data_tools,huggingface]) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5,>=4->camel-ai->camel-ai[data_tools,huggingface]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5,>=4->camel-ai->camel-ai[data_tools,huggingface]) (0.24.0)\n",
            "Requirement already satisfied: latex2sympy2_extended==1.10.1 in /usr/local/lib/python3.11/dist-packages (from math-verify<0.8,>=0.7.0->camel-ai->camel-ai[data_tools,huggingface]) (1.10.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from latex2sympy2_extended==1.10.1->math-verify<0.8,>=0.7.0->camel-ai->camel-ai[data_tools,huggingface]) (1.13.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime<=4.13.2,>=4.9.3 in /usr/local/lib/python3.11/dist-packages (from latex2sympy2_extended==1.10.1->math-verify<0.8,>=0.7.0->camel-ai->camel-ai[data_tools,huggingface]) (4.13.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.68.0->camel-ai->camel-ai[data_tools,huggingface]) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.68.0->camel-ai->camel-ai[data_tools,huggingface]) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.68.0->camel-ai->camel-ai[data_tools,huggingface]) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2,>=1.5.3->camel-ai->camel-ai[data_tools,huggingface]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2,>=1.5.3->camel-ai->camel-ai[data_tools,huggingface]) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.10,>=1.9->camel-ai->camel-ai[data_tools,huggingface]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.10,>=1.9->camel-ai->camel-ai[data_tools,huggingface]) (2.23.4)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile<0.14,>=0.13->camel-ai->camel-ai[data_tools,huggingface]) (1.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.11/dist-packages (from textblob<0.18,>=0.17.1->camel-ai->camel-ai[data_tools,huggingface]) (3.9.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->camel-ai->camel-ai[data_tools,huggingface]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->camel-ai->camel-ai[data_tools,huggingface]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->camel-ai->camel-ai[data_tools,huggingface]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->camel-ai->camel-ai[data_tools,huggingface]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->camel-ai->camel-ai[data_tools,huggingface]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->camel-ai->camel-ai[data_tools,huggingface]) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->camel-ai->camel-ai[data_tools,huggingface]) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->camel-ai->camel-ai[data_tools,huggingface]) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->camel-ai->camel-ai[data_tools,huggingface]) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->camel-ai->camel-ai[data_tools,huggingface]) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->camel-ai->camel-ai[data_tools,huggingface]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->camel-ai->camel-ai[data_tools,huggingface]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->camel-ai->camel-ai[data_tools,huggingface]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->camel-ai->camel-ai[data_tools,huggingface]) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->camel-ai->camel-ai[data_tools,huggingface]) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->latex2sympy2_extended==1.10.1->math-verify<0.8,>=0.7.0->camel-ai->camel-ai[data_tools,huggingface]) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4->camel-ai->camel-ai[data_tools,huggingface]) (0.21.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile<0.14,>=0.13->camel-ai->camel-ai[data_tools,huggingface]) (2.22)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<4,>=3->camel-ai->camel-ai[data_tools,huggingface]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<4,>=3->camel-ai->camel-ai[data_tools,huggingface]) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<4,>=3->camel-ai->camel-ai[data_tools,huggingface]) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<4,>=3->camel-ai->camel-ai[data_tools,huggingface]) (6.3.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<4,>=3->camel-ai->camel-ai[data_tools,huggingface]) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<4,>=3->camel-ai->camel-ai[data_tools,huggingface]) (1.18.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.1->textblob<0.18,>=0.17.1->camel-ai->camel-ai[data_tools,huggingface]) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.1->textblob<0.18,>=0.17.1->camel-ai->camel-ai[data_tools,huggingface]) (1.4.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4,>=3->camel-ai->camel-ai[data_tools,huggingface]) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4,>=3->camel-ai->camel-ai[data_tools,huggingface]) (2.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers<0.26,>=0.25.0->camel-ai->camel-ai[data_tools,huggingface]) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->camel-ai->camel-ai[data_tools,huggingface]) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Optional: Install camel if you don't have it\n",
        "!pip install \"git+https://github.com/camel-ai/camel.git@bec98152d3df3dd1731b78208608b4a9438a010e#egg=camel-ai[huggingface, data_tools]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtQdrgZNUg4e"
      },
      "source": [
        "The Loong *environment* is a unified interface that can be used for Synthetic Data Generation, RL training and Benchmarking agents. It integrates all the primitives that we implemented at CAMEL to provide a nice interface for developers and researchers. In this cookbook, we will explain how to initialize a *Single Step Environment* to generate synthetic data. More cookbooks about RL training and how to customize the environment are coming soon.\n",
        "\n",
        "This type of environment is called a *single step* environment, because the agent only does one step. It gets a question sampled from the dataset (the initial state / observation) and then answers. The answer is then scored according to the reward function. Recently, rules-based reward functions, i.e. functions without any learnable parameters, have been successfully used to do RL with LLMs as as policy.\n",
        "\n",
        "Since many RL algorithms (such as GRPO) need multiple rollouts at each step, batching is important to guarantee concurrency / parallelism. Our `SingleStepEnv` supports batching (both `reset` and `step`), but for the sake of simplicity, we will not use batching for this cookbook. We will soon release another cookbook dedicated to batching.\n",
        "\n",
        "First, we have to load a dataset from which we will sample questions. The dataset can be either a `StaticDataset`, which is finite, or it can be a `BaseGenerator`, which is an infinite supply of question - answer pairs, synthetically generated in some way, depending on the implementation. To seed the generative process of the `BaseGenerator`, we need to seed it with a *seed dataset*. Each generator uses the seed dataset it was initialized with to generate new data.\n",
        "\n",
        "In this cookbook, we will use the `FewShotGenerator`, which will generate new data points by doing simple few-shot prompting, using random data points from the seed dataset as examples.\n",
        "\n",
        "A seed dataset can easily be thought of as a type of `StaticDataset`, so let's initialize our seed dataset as such a `StaticDataset`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sZdba1LJUg4e"
      },
      "outputs": [],
      "source": [
        "from camel.datasets import StaticDataset\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"camel-ai/loong\", split=\"graph_discrete_math\")\n",
        "\n",
        "seed_dataset = StaticDataset(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add `%load_ext cudf.pandas` before importing pandas to speed up operations using GPU"
      ],
      "metadata": {
        "id": "mKYpRtztKp0X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-l7UHBUKY-rJ",
        "outputId": "de0724fb-18de-4687-b0bb-40e6ca84b33b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Given an undirected path graph with 10 vertices, what is the largest independent node set and the list of maximal cliques that can be obtained by repeatedly removing cliques from the graph? Return the result as a 2-tuple, i.e., (largest_independent_node_set, list_of_maximal_cliques), where the first element is a set of nodes in sorted order and the second element is a list of maximal cliques in sorted order (each clique is represented as a set of nodes).\n",
            "Final Answer: ({0, 2, 4, 6, 9}, [{0, 1}, {2, 3}, {4, 5}, {6, 7}, {8, 9}])\n"
          ]
        }
      ],
      "source": [
        "example = seed_dataset[0]\n",
        "\n",
        "print(f\"Question: {example.question}\")\n",
        "print(f\"Final Answer: {example.final_answer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h-s-T6yUg4f"
      },
      "source": [
        "The `FewShotGenerator` needs a python interpreter to compute a synthetic answer (pseudo ground truth) from the code it generated. For this, let's define a `PythonVerifier`.\n",
        "\n",
        "Note: We will soon use dedicated CAMEL-based code interpreters instead of repurposing our Python verifier for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wrkXNgTHUg4f"
      },
      "outputs": [],
      "source": [
        "from camel.verifiers import PythonVerifier\n",
        "from camel.agents import ChatAgent\n",
        "from camel.extractors import BaseExtractor, BoxedStrategy\n",
        "\n",
        "interpreter = PythonVerifier(required_packages=[\"numpy\", \"networkx\"])\n",
        "await interpreter.setup(uv=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0LJzJHxUg4f"
      },
      "source": [
        "Lastly, we need a model backend for the generation agent. Let's use the `ModelFactory` to create one.\n",
        "\n",
        "Note: We use GPT-4o mini as a default here, hence we load our OpenAI API key. Feel free to use other models!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz_GyOdTUg4f",
        "outputId": "33d13dd7-ccc4-45e4-b075-803e76fa47c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "openai_api_key = getpass('Enter your API key: ')\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zYpsSJ1HUg4g"
      },
      "outputs": [],
      "source": [
        "from camel.models import ModelFactory\n",
        "from camel.types import ModelPlatformType, ModelType\n",
        "from camel.configs import ChatGPTConfig\n",
        "from camel.datasets import FewShotGenerator\n",
        "\n",
        "model = ModelFactory.create(\n",
        "    model_platform=ModelPlatformType.OPENAI,\n",
        "    model_type=ModelType.GPT_4O_MINI,\n",
        "    model_config_dict=ChatGPTConfig().as_dict(),\n",
        ")\n",
        "\n",
        "# Note: When the generator is exhausted, it will create 20 new datapoints by default\n",
        "# To save money on the API, let's set this number to 2 instead, so we don't generate more than we need.\n",
        "generator = FewShotGenerator(\n",
        "    buffer=2, seed_dataset=seed_dataset, verifier=interpreter, model=model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrNvc945efey"
      },
      "source": [
        "Let's next create a verifier that extracts content inside a `\\boxed{...}` from the llm response and compares it semantically to the reference answer.\n",
        "\n",
        "Since we want Loong to be flexible, we utilize built a dedicated extraction module that defines how to parse the llm response and extract the relevant portion that we want to compare. A dedicated cookbook on how to use it is coming soon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tgjrKwl0eekB"
      },
      "outputs": [],
      "source": [
        "from camel.verifiers import PythonVerifier\n",
        "from camel.agents import ChatAgent\n",
        "from camel.extractors import BaseExtractor, BoxedStrategy\n",
        "\n",
        "# Initialize extractor\n",
        "extractor = BaseExtractor([[BoxedStrategy()]])\n",
        "await extractor.setup()\n",
        "\n",
        "\n",
        "verifier = PythonVerifier(extractor=extractor, required_packages=[\"numpy\", \"networkx\"])\n",
        "await verifier.setup(uv=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQFa-ZJoUg4g"
      },
      "source": [
        "Now that our generator and verifier are all set up, let's create a `SingleStepEnv` with it.\n",
        "\n",
        "We can then call `env.reset()` to sample the underlying generator, which returns that question as an observation. We can then feed this observation into the CoT agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL81svP-Ug4g",
        "outputId": "86217333-094c-4bd7-ca27-28803864c9ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:camel.camel.datasets.few_shot_generator:Verifier issue: Verifier unsuccessful, response: status=<VerificationOutcome.ERROR: 'error'> result='' duration=0.22823548316955566 timestamp=datetime.datetime(2025, 4, 4, 14, 44, 16, 781812) metadata={'attempt': 1} error_message='Solution code error:\\nTraceback (most recent call last):\\n  File \"/tmp/tmpfjumbxbz.py\", line 6, in <module>\\n    g.add_edges_from([(1, 3), (1, 4), (2, 3)])\\n    ^\\nNameError: name \\'g\\' is not defined. Did you mean: \\'G\\'?', retrying... (1/10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation: question='In a complete graph with 5 vertices (node 0, 1, 2, 3, 4), what are the eccentricities of each node? Return the eccentricities as a dictionary with the node as the key and its eccentricity as the value.' context={} metadata={}\n"
          ]
        }
      ],
      "source": [
        "from camel.environments import SingleStepEnv\n",
        "\n",
        "env = SingleStepEnv(generator, verifier)\n",
        "await env.setup()\n",
        "\n",
        "obs = await env.reset(seed=42)\n",
        "\n",
        "print(f\"Observation: {obs}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jTmV405Ug4g"
      },
      "source": [
        "The agent would then process this observation and select an action, which it would feed into the `step` function, which feeds it back into the environment. More specifically, it feeds it back into the verifier, which then returns a reward based on whether the llm response and reference answer are aligned or not.\n",
        "\n",
        "Let's first define a CAMEL agent and feed it the observation. Afterwards, we use the `step` function of the environment to get a reward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGC17YF8Ug4g",
        "outputId": "7ada8719-cf58-414b-87f4-e9ce5b2c8a3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the episode done?: True\n",
            "Next Observation: question='Episode ended. This is just a placeholder.' context={} metadata=None\n",
            "Reward: 10.0\n",
            "Info: {'proposed_solution': 'To find the eccentricities of each node in a complete graph with 5 vertices, we need to first understand the definition of eccentricity in graph theory.\\n\\n**Step 1: Understanding Graph Basics**\\n\\nA complete graph, denoted as \\\\( K_n \\\\), is a graph where every pair of distinct vertices is connected by a unique edge. For \\\\( n = 5 \\\\), the graph \\\\( K_5 \\\\) has 5 vertices: 0, 1, 2, 3, and 4. \\n\\n**Step 2: Definition of Eccentricity**\\n\\nThe eccentricity \\\\( e(v) \\\\) of a vertex \\\\( v \\\\) is defined as the greatest distance from \\\\( v \\\\) to any other vertex in the graph. In mathematical terms, if \\\\( d(u, v) \\\\) is the distance (shortest path length) between vertices \\\\( u \\\\) and \\\\( v \\\\), then:\\n\\\\[\\ne(v) = \\\\max_{u \\\\in V} d(u, v)\\n\\\\]\\nwhere \\\\( V \\\\) is the set of all vertices in the graph.\\n\\n**Step 3: Distance in a Complete Graph**\\n\\nIn a complete graph, the distance between any two distinct vertices is always 1, because they are directly connected by an edge. Therefore, for any vertex \\\\( v \\\\), the distance to any other vertex \\\\( u \\\\) will be:\\n\\n- \\\\( d(v, u) = 1 \\\\) if \\\\( u \\\\neq v \\\\)\\n- \\\\( d(v, v) = 0 \\\\)\\n\\n**Step 4: Calculating Eccentricities**\\n\\nSince each vertex is only one edge away from every other vertex in \\\\( K_5 \\\\), the maximal distance (and therefore the eccentricity) for each vertex is 1. Therefore:\\n\\\\[\\ne(0) = 1, \\\\quad e(1) = 1, \\\\quad e(2) = 1, \\\\quad e(3) = 1, \\\\quad e(4) = 1\\n\\\\]\\n\\n**Step 5: Creating the Dictionary of Eccentricities**\\n\\nWe can represent the eccentricities of the vertices in a dictionary format:\\n\\n```python\\neccentricities = {\\n    0: 1,\\n    1: 1,\\n    2: 1,\\n    3: 1,\\n    4: 1\\n}\\n```\\n\\nThus, the eccentricities of each node in a complete graph with 5 vertices are as follows:\\n\\n\\\\[\\n\\\\text{Eccentricities} = \\\\{0: 1, 1: 1, 2: 1, 3: 1, 4: 1\\\\}\\n\\\\]\\n\\n**Final Answer**\\n\\nThe eccentricities can be written in a Python expression as:\\n```python\\n{0: 1, 1: 1, 2: 1, 3: 1, 4: 1}\\n```\\n\\nIn the boxed format, the final answer is:\\n\\n\\\\[\\n\\\\boxed{{0: 1, 1: 1, 2: 1, 3: 1, 4: 1}}\\n\\\\]', 'verification_result': VerificationResult(status=<VerificationOutcome.SUCCESS: 'success'>, result='{0: 1, 1: 1, 2: 1, 3: 1, 4: 1}', duration=0.0004589557647705078, timestamp=datetime.datetime(2025, 4, 4, 15, 41, 34, 810450), metadata={'attempt': 1}, error_message=None), 'state': DataPoint(question='In a complete graph with 5 vertices (node 0, 1, 2, 3, 4), what are the eccentricities of each node? Return the eccentricities as a dictionary with the node as the key and its eccentricity as the value.', final_answer='{0: 1, 1: 1, 2: 1, 3: 1, 4: 1}', rationale='import networkx as nx\\n\\nG = nx.complete_graph(5)\\neccentricities = nx.eccentricity(G)\\nprint(eccentricities)', metadata={'synthetic': 'True', 'created': '2025-04-04T14:41:48.644380', 'generator': 'few_shot'}), 'rewards_dict': {'correctness': 10.0}}\n"
          ]
        }
      ],
      "source": [
        "agent = ChatAgent(model=model)\n",
        "from camel.environments.models import Action\n",
        "USER_PROMPT = r\"\"\"\n",
        "You are an agent designed to answer mathematical questions with clarity and precision. Your task is to provide a step-by-step explanation for\n",
        "any mathematical problem posed by the user, ensuring the response is easy to follow. Adhere to these guidelines:\n",
        "Analyze the mathematical question carefully and break down the solution process into clear, logical steps.\n",
        "Use natural language to explain each step, incorporating LaTeX notation (e.g., $x + 2$)\n",
        "for mathematical expressions when helpful. Conclude your response with the final answer enclosed\n",
        "in a LaTeX \\boxed{} environment (e.g., \\boxed{5}).\n",
        "Place this at the end of your explanation as a standalone statement.\n",
        "It should be a Python expression, for example \"[1, 2, 3]\" for a list.\n",
        "\n",
        "The question you should answer is: \"\"\"\n",
        "\n",
        "response = agent.step(USER_PROMPT + obs.question).msgs[0].content\n",
        "\n",
        "action = Action(llm_response=response)\n",
        "next_obs, reward, done, info = await env.step(action)\n",
        "\n",
        "agent.reset()\n",
        "\n",
        "print(f\"Is the episode done?: {done}\")\n",
        "print(f\"Next Observation: {next_obs}\")\n",
        "print(f\"Reward: {reward}\")\n",
        "print(f\"Info: {info}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HoYlql1UIaW"
      },
      "source": [
        "As you can see, the `step` function does exactly what you would expect it to do, if you know how Gym works.\n",
        "\n",
        "`done` is always `True` in this case, since we are in a *single step* environment. This is also the reason that `next_obs` is a placeholder observation, as there is no next observation for this episode.\n",
        "\n",
        "`reward` is the **total** reward for this action. By default, we only use an *accuracy reward*, i.e. $0$ if verifier returns that llm response and synthetic answer are not the same and $10$ otherwise. The accuracy reward can be manually set to any number by simply overriding the attribute of the environment (e.g. `env.ACCURACY_REWARD = 1`). We will add a cookbook soon that shows how to create a custom reward by extending `SingleStepEnv`.\n",
        "\n",
        "Finally, `info` is a dict containing a lot of information about the specifc interaction with the environment. For example, it contains a dict listing the different components of the total reward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01crFDLvbNCz"
      },
      "source": [
        "### Environment Loop\n",
        "\n",
        "Let's look at how this would look like in a typical loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tv2EM-HqbPRn",
        "outputId": "4892570f-5ebb-4cf3-c8fa-2fccadb90f52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward at step 0: 10.0\n",
            "Reward at step 1: 0.0\n",
            "Reward at step 2: 10.0\n",
            "Reward at step 3: 10.0\n"
          ]
        }
      ],
      "source": [
        "for i in range(4):\n",
        "  obs = await env.reset()\n",
        "  response = agent.step(USER_PROMPT + obs.question).msgs[0].content\n",
        "  action = Action(llm_response=response)\n",
        "  next_obs, reward, done, info = await env.step(action)\n",
        "  print(f\"Reward at step {i}: {reward}\")\n",
        "  agent.reset() # to clear context window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOsSOn3jUIaW"
      },
      "source": [
        "In practice, the agent's model backend would point at an inference engine like vllm or SGLang. After each `step` call (or batches thereof), we would feed the reward for the action into a training framework like *veRL* or *HuggingFace TRL*. These would update the model backend that the agent points to, such that after every training step, the new iteration of the model is used for choosing an action."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZdVJlblUIaW"
      },
      "source": [
        "Naturally, this setup may seem overkill. In the near future, we will explore multi-step environments like Chess, Go and GAIA, which is why we created this framework to unify RL training. We will work in the coming weeks to make it more efficient and release educational material on how to use it.\n",
        "\n",
        "We are looking forward to see what you build using the Loong environment! Feel free to share it with us on ùïè."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}