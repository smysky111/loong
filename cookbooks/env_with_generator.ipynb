{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vewJOQqLUh2i",
        "outputId": "732669d6-fb77-4b31-c401-60910554a5b1"
      },
      "outputs": [],
      "source": [
        "# 锔 Clone and install camel from GitHub\n",
        "!git clone https://github.com/camel-ai/camel/\n",
        "%cd camel\n",
        "\n",
        "#  Install in editable mode with dependencies\n",
        "!pip install \"git+https://github.com/camel-ai/camel.git@master#egg=camel-ai[all]\"\n",
        "# 猬锔 Return to notebook root\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp9lQNIvUg4d"
      },
      "source": [
        "# Working with the Loong environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtQdrgZNUg4e"
      },
      "source": [
        "The Loong *environment* is a unified interface that can be used for Synthetic Data Generation, RL training and Benchmarking agents. It integrates all the primitives that we implemented at CAMEL to provide a nice interface for developers and researchers. In this cookbook, we will explain how to initialize a *Single Step Environment* to generate synthetic data. More cookbooks about RL training and how to customize the environment are coming soon.\n",
        "\n",
        "This type of environment is called a *single step* environment, because the agent only does one step. It gets a question sampled from the dataset (the initial state / observation) and then answers. The answer is then scored according to the reward function. Recently, rules-based reward functions, i.e. functions without any learnable parameters, have been successfully used to do RL with LLMs as as policy.\n",
        "\n",
        "Since many RL algorithms (such as GRPO) need multiple rollouts at each step, batching is important to guarantee concurrency / parallelism. This notebook will show how to use batched environments.\n",
        "\n",
        "First, we have to load a dataset from which we will sample questions. The dataset can be either a `StaticDataset`, which is finite or it can be a `BaseGenerator`, which is an infinite supply of question - answer pairs, synthetically generated in some way, depending on the implementation. To seed the generative process of the `BaseGenerator`, we need to seed it with a *seed dataset*. Each generator uses the seed dataset it was initialized with to generate new data.\n",
        "\n",
        "In this cookbook, we will use the `FewShotGenerator`, which will generate new data points by doing simple few-shot prompting, using random data points from the seed dataset as examples.\n",
        "\n",
        "A seed dataset can easily be thought of as a type of `StaticDataset`, so let's initialize our seed dataset as such a `StaticDataset`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "sZdba1LJUg4e"
      },
      "outputs": [],
      "source": [
        "from camel.datasets import StaticDataset\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset_dict = load_dataset(\"camel-ai/loong\")\n",
        "dataset = dataset_dict[\"train\"].filter(lambda example: example['source_type'] == 'graph_discrete_math')\n",
        "\n",
        "seed_dataset = StaticDataset(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-l7UHBUKY-rJ",
        "outputId": "f0d1ea78-ac89-4ac3-98dd-25d21772ecc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataPoint(question='Given an undirected path graph with 10 vertices, what is the largest independent node set and the list of maximal cliques that can be obtained by repeatedly removing cliques from the graph? Return the result as a 2-tuple, i.e., (largest_independent_node_set, list_of_maximal_cliques), where the first element is a set of nodes in sorted order and the second element is a list of maximal cliques in sorted order (each clique is represented as a set of nodes).', final_answer='({0, 2, 4, 6, 9}, [{0, 1}, {2, 3}, {4, 5}, {6, 7}, {8, 9}])', rationale='import networkx as nx\\n\\nG = nx.path_graph(10)\\nprint(nx.approximation.clique_removal(G))', metadata=None)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seed_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h-s-T6yUg4f"
      },
      "source": [
        "The `FewShotGenerator` needs a python interpreter to compute a pseudo ground truth from the code it generated. For this, let's define a `PythonVerifier`.\n",
        "\n",
        "Note: We will soon use dedicated CAMEL-based code interpreters instead of repurposing our Python verifier for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wrkXNgTHUg4f"
      },
      "outputs": [],
      "source": [
        "from camel.verifiers import PythonVerifier\n",
        "from camel.agents import ChatAgent\n",
        "from camel.extractors import BaseExtractor, BoxedStrategy\n",
        "\n",
        "interpreter = PythonVerifier(required_packages=[\"numpy\", \"networkx\"])\n",
        "await interpreter.setup(uv=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0LJzJHxUg4f"
      },
      "source": [
        "Lastly, we need a model backend for the generation agent. Let's use the `ModelFactory` to create one.\n",
        "\n",
        "Note: We use GPT-4o mini as a default here, hence we load our OpenAI API key. Feel free to use other models!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz_GyOdTUg4f",
        "outputId": "d6c7e5dd-180b-4d7b-8889-91876611b7e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your API key: 路路路路路路路路路路\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Prompt for the API key securely\n",
        "openai_api_key = getpass('Enter your API key: ')\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "zYpsSJ1HUg4g"
      },
      "outputs": [],
      "source": [
        "from camel.models import ModelFactory\n",
        "from camel.types import ModelPlatformType, ModelType\n",
        "from camel.configs import ChatGPTConfig\n",
        "from camel.datasets import FewShotGenerator\n",
        "\n",
        "model = ModelFactory.create(\n",
        "    model_platform=ModelPlatformType.OPENAI,\n",
        "    model_type=ModelType.GPT_4O_MINI,\n",
        "    model_config_dict=ChatGPTConfig().as_dict(),\n",
        ")\n",
        "\n",
        "# Note: When the generator needs to create new datapoints, it will by default create 20 new datapoints\n",
        "# Since we are paying for the API, let's set this number to 2 instead\n",
        "generator = FewShotGenerator(\n",
        "    puffer=2, seed_dataset=seed_dataset, verifier=interpreter, model=model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrNvc945efey"
      },
      "source": [
        "Let's next create a verifier that extracts content inside a `\\boxed{...}` from the llm response and compares it semantically to the reference answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "tgjrKwl0eekB"
      },
      "outputs": [],
      "source": [
        "from camel.verifiers import PythonVerifier\n",
        "from camel.agents import ChatAgent\n",
        "from camel.extractors import BaseExtractor, BoxedStrategy\n",
        "\n",
        "# Initialize extractor\n",
        "extractor = BaseExtractor([[BoxedStrategy()]])\n",
        "\n",
        "\n",
        "verifier = PythonVerifier(extractor=extractor, required_packages=[\"numpy\", \"networkx\"])\n",
        "await verifier.setup(uv=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQFa-ZJoUg4g"
      },
      "source": [
        "Now that our generator and verifier are all set up, let's create a `SingleStepEnv` with it.\n",
        "\n",
        "We can then call `env.reset()` to sample the underlying generator, which returns that question as an observation. We can then feed this observation into the CoT agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL81svP-Ug4g",
        "outputId": "a031b5e3-deaa-40db-f8b4-19704d401a79"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:camel.camel.environments.single_step:reset() called on un-setup environment. Setting up...\n",
            "WARNING:camel.camel.datasets.few_shot_generator:Verifier issue: Verifier unsuccessful, response: status=<VerificationOutcome.ERROR: 'error'> result='' duration=0.7647051811218262 timestamp=datetime.datetime(2025, 4, 1, 13, 25, 43, 144308) metadata={'attempt': 1} error_message='Solution code error:\\nTraceback (most recent call last):\\n  File \"/tmp/tmpg5yujva6.py\", line 3, in <module>\\n    G = nx.bipartite.random_graph(3, 3)\\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/tmp/tmpzququ834/lib/python3.11/site-packages/networkx/utils/decorators.py\", line 788, in func\\n    return argmap._lazy_compile(__wrapper)(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nTypeError: random_graph() missing 1 required positional argument: \\'p\\'', retrying... (1/10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "question='In a directed graph defined by the edges connecting nodes as follows: (1, 2), (2, 3), (3, 4), and (4, 1), what is the in-degree of node 3? Return the in-degree as an integer.' context={} metadata={}\n"
          ]
        }
      ],
      "source": [
        "from camel.environments import Action, SingleStepEnv\n",
        "\n",
        "env = SingleStepEnv(generator, verifier)\n",
        "\n",
        "obs = await env.reset(seed=42)\n",
        "\n",
        "print(obs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jTmV405Ug4g"
      },
      "source": [
        "The agent would then process this observation and select an action, which it would feed into the `step` function, which feeds it back into the environment. More specifically, it feeds it back into the verifier, which then returns a reward based on whether the llm response and reference answer are aligned or not.\n",
        "\n",
        "Let's first define a CAMEL agent and feed it the observation. Afterwards, we use the `step` function of the environment to get a reward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "hGC17YF8Ug4g"
      },
      "outputs": [],
      "source": [
        "agent = ChatAgent(model=model)\n",
        "\n",
        "USER_PROMPT = r\"\"\"\n",
        "You are an agent designed to answer mathematical questions with clarity and precision. Your task is to provide a step-by-step explanation for\n",
        "any mathematical problem posed by the user, ensuring the response is easy to follow. Adhere to these guidelines:\n",
        "Analyze the mathematical question carefully and break down the solution process into clear, logical steps.\n",
        "Use natural language to explain each step, incorporating LaTeX notation (e.g., $x + 2$)\n",
        "for mathematical expressions when helpful. Conclude your response with the final answer enclosed\n",
        "in a LaTeX \\boxed{} environment (e.g., \\boxed{5}).\n",
        "Place this at the end of your explanation as a standalone statement.\n",
        "It should be a Python expression, for example \"[1, 2, 3]\" for a list.\n",
        "\n",
        "The question you should answer is: \"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzaERjmhUg4g"
      },
      "source": [
        "Finally, let's compare the agents output to our pseudo ground truth:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJpOeb7AUg4g",
        "outputId": "6af65adb-e569-43d7-b935-13a09cc41617"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(Observation(question='Episode ended. This is just a placeholder.', context={}, metadata=None), 10.0, True, {'proposed_solution': \"To determine the diameter of a Platonic Tetrahedral Graph, we'll follow a step-by-step process to clearly explain the concept and the calculations involved.\\n\\n### Step 1: Understand the Structure of the Tetrahedral Graph\\nA Platonic Tetrahedral Graph corresponds to a regular tetrahedron, which consists of:\\n- **4 vertices**: Let's label them as \\\\( A \\\\), \\\\( B \\\\), \\\\( C \\\\), and \\\\( D \\\\).\\n- **6 edges**: The edges connect these vertices as follows:\\n  - \\\\( A \\\\) to \\\\( B \\\\)\\n  - \\\\( A \\\\) to \\\\( C \\\\)\\n  - \\\\( A \\\\) to \\\\( D \\\\)\\n  - \\\\( B \\\\) to \\\\( C \\\\)\\n  - \\\\( B \\\\) to \\\\( D \\\\)\\n  - \\\\( C \\\\) to \\\\( D \\\\)\\n\\n### Step 2: Define the Diameter of a Graph\\nThe **diameter** of a graph is defined as the largest distance between any pair of vertices in the graph. The distance between two vertices is the minimum number of edges that need to be traversed to connect them.\\n\\n### Step 3: Calculate Distances Between Vertices\\nSince each vertex in a tetrahedral graph is connected directly to every other vertex, we can evaluate the distances:\\n- Distance between \\\\( A \\\\) and \\\\( B \\\\): **1** (they are directly connected)\\n- Distance between \\\\( A \\\\) and \\\\( C \\\\): **1** (they are directly connected)\\n- Distance between \\\\( A \\\\) and \\\\( D \\\\): **1** (they are directly connected)\\n- Distance between \\\\( B \\\\) and \\\\( C \\\\): **1** (they are directly connected)\\n- Distance between \\\\( B \\\\) and \\\\( D \\\\): **1** (they are directly connected)\\n- Distance between \\\\( C \\\\) and \\\\( D \\\\): **1** (they are directly connected)\\n\\n### Step 4: Find the Maximum Distance\\nSince all pairs of vertices are directly connected, the maximum distance between any pair of vertices in this graph is:\\n\\\\[\\n\\\\text{Maximum Distance} = 1\\n\\\\]\\n\\n### Step 5: Determine the Diameter\\nSince no pair of vertices has a distance greater than 1, the diameter of the Tetrahedral Graph is:\\n\\\\[\\n\\\\text{Diameter} = 1\\n\\\\]\\n\\n### Conclusion\\nThe diameter of a Platonic Tetrahedral Graph is therefore:\\n\\\\[\\n\\\\boxed{1}\\n\\\\]\", 'verification_result': VerificationResult(status=<VerificationOutcome.SUCCESS: 'success'>, result='1', duration=0.0004470348358154297, timestamp=datetime.datetime(2025, 4, 1, 13, 28, 17, 138596), metadata={'attempt': 1}, error_message=None), 'state': DataPoint(question='For a Platonic Tetrahedral Graph, what is the diameter of the graph?', final_answer='1', rationale='import networkx as nx\\n\\nG = nx.tetrahedral_graph()\\nprint(nx.diameter(G))', metadata={'synthetic': 'True', 'created': '2025-04-01T13:25:47.394576', 'generator': 'few_shot'}), 'rewards_dict': {'correctness': 10.0}})\n"
          ]
        }
      ],
      "source": [
        "response = agent.step(USER_PROMPT + obs.question).msgs[0].content\n",
        "\n",
        "result = await env.step(Action(index=0, llm_response=response))\n",
        "\n",
        "agent.reset()\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01crFDLvbNCz"
      },
      "source": [
        "### Environment Loop\n",
        "\n",
        "Let's look at how this would look like in a loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "Tv2EM-HqbPRn",
        "outputId": "b8a47f33-ede0-42a3-fa13-27a082061926"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:camel.camel.datasets.few_shot_generator:Verifier issue: Verifier unsuccessful, response: status=<VerificationOutcome.ERROR: 'error'> result='' duration=0.3660871982574463 timestamp=datetime.datetime(2025, 4, 1, 13, 31, 40, 877287) metadata={'attempt': 1} error_message='Solution code error:\\nTraceback (most recent call last):\\n  File \"/tmp/tmp17obkf_v.py\", line 3, in <module>\\n    page_rank = nx.pagerank(G, alpha=0.85)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/tmp/tmpzququ834/lib/python3.11/site-packages/networkx/utils/decorators.py\", line 788, in func\\n    return argmap._lazy_compile(__wrapper)(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"<class \\'networkx.utils.decorators.argmap\\'> compilation 16\", line 3, in argmap_pagerank_13\\n  File \"/tmp/tmpzququ834/lib/python3.11/site-packages/networkx/utils/backends.py\", line 967, in __call__\\n    return self.orig_func(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/tmp/tmpzququ834/lib/python3.11/site-packages/networkx/algorithms/link_analysis/pagerank_alg.py\", line 111, in pagerank\\n    return _pagerank_scipy(\\n           ^^^^^^^^^^^^^^^^\\n  File \"/tmp/tmpzququ834/lib/python3.11/site-packages/networkx/algorithms/link_analysis/pagerank_alg.py\", line 454, in _pagerank_scipy\\n    import scipy as sp\\nModuleNotFoundError: No module named \\'scipy\\'', retrying... (1/10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n",
            "10.0\n",
            "10.0\n"
          ]
        },
        {
          "ename": "CancelledError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-9e324c4bdb7c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUSER_PROMPT\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mnext_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm_response\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# to clear context window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/camel/environments/single_step.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             verification_results = await self.verifier.verify_batch(\n\u001b[0m\u001b[1;32m    338\u001b[0m                 \u001b[0msolutions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproposed_solutions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0mreference_answers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mground_truths\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore [arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/camel/verifiers/base.py\u001b[0m in \u001b[0;36mverify_batch\u001b[0;34m(self, solutions, reference_answers, raise_on_error)\u001b[0m\n\u001b[1;32m    378\u001b[0m             ]\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0mbatch_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mverification_tasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0mall_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCancelledError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for i in range(3):\n",
        "  obs = await env.reset()\n",
        "  response = agent.step(USER_PROMPT + obs.question).msgs[0].content\n",
        "\n",
        "  next_obs, reward, done, info = await env.step(Action(llm_response=response))\n",
        "  print(f\"Reward at step {i}: {reward}\")\n",
        "  agent.reset() # to clear context window"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
